---
title: Analyzing Presentation Traffic
date: 2006-10-19T12:00:00-04:00
---

  
<p>
(... or how to use Digital Signal Processing on your log files ...)
</p>
<p>
  One of the benefits of writing your own presentation software is that you
  can do web-friendly things like giving each and every page 
  of <a href="http://bitworking.org/projects/cascon06/">your presentation</a> it's own URI. That lets lots of cool stuff happen
  like allowing search engines to spider the content and allowing
  people to link directly to a slide in the deck. It also lets me
  monitor how people look at the slides by just looking at my traffic logs. Now the 
  first easy metric is just how many people have looked at the 
  slides, but I got curious and wanted to see how many people actually
  made it all the way through to the end of my presentation.
</p>

  
<p>
  Here is a simple Python program to load up the server logs
  and count the number of hits on each page of the presentation; printing
  the results as a comma separated list.
</p>
<pre><code><span class="PreProc">import</span> re

slide_regex = re.compile(<span class="Normal">"</span><span class="Constant">GET /projects/cascon06/(\d+).html</span><span class="Normal">"</span>)
hits = [0] * 130

<span class="Statement">def</span> <span class="Identifier">analyze</span>(filename):
    <span class="Statement">for</span> line <span class="Statement">in</span> file(filename, <span class="Normal">"</span><span class="Constant">r</span><span class="Normal">"</span>):
        match = slide_regex.search(line)
        <span class="Statement">if</span> match:
            index = int(match.groups()[0])
            <span class="Statement">if</span> index &gt; 0 <span class="Statement">and</span> index &lt; 130:
                hits[int(match.groups()[0])] += 1

    <span class="Statement">print</span> <span class="Normal">"</span><span class="Constant">,</span><span class="Normal">"</span>.join([str(i) <span class="Statement">for</span> i <span class="Statement">in</span> hits[2:]])

analyze(<span class="Normal">"</span><span class="Constant">20061018.log</span><span class="Normal">"</span>)
</code></pre>
<p>
   Note that the code doesn't report the first two
   values in <code>hits</code>. That's because there
   is no slide <tt>0.html</tt> and <tt>1.html</tt> has
   <tt>index.html</tt> as an alias. 
   I got a copy of the logs around 11AM yesterday and 
   the output of the program looks like this:
</p>
<pre><code>   217,206,201,211,200,195,185,187,185,180,178,175,175,179,
   181,178,176,178,177,175,172,176,175,167,163,162,166,166,
   164,163,160,157,154,150,148,144,142,141,139,138,137,143,
   146,141,138,137,134,140,141,140,140,133,133,127,125,137,
   135,121,120,121,122,121,121,120,120,120,123,124,123,120,
   123,125,122,120,120,123,122,122,125,126,125,124,125,123,
   120,121,121,119,124,128,124,121,121,120,125,126,118,118,
   117,111,112,108,100,103,102,99,99,97,97,100,103,106,99,97,
   96,96,97,98,98,96,96,96,94,95,95,97,104,96</code></pre>
<p>
   If you look at the first and last numbers in the list,
   217 and 96, you can see that approximately half of the  
   people that started actually made it all the way to the end.
   I'm pretty impressed with that.
</p>
<p>
  I expected the data to be perfectly montonic, always decreasing
  as you went further and further into the presentation, but
  that 104 as the second to last value points to something
  else going on. Let's graph the data. Luckily
  the data is perfectly formatted for the 
  <a href="http://bitworking.org/projects/sparklines/">sparkline generator</a>.
</p>
<p>
<img src="http://bitworking.org/projects/sparklines/spark.cgi?type=discrete&amp;d=217,206,201,211,200,195,185,187,185,180,178,175,175,179,181,178,176,178,177,175,172,176,175,167,163,162,166,166,164,163,160,157,154,150,148,144,142,141,139,138,137,143,146,141,138,137,134,140,141,140,140,133,133,127,125,137,135,121,120,121,122,121,121,120,120,120,123,124,123,120,123,125,122,120,120,123,122,122,125,126,125,124,125,123,120,121,121,119,124,128,124,121,121,120,125,126,118,118,117,111,112,108,100,103,102,99,99,97,97,100,103,106,99,97,96,96,97,98,98,96,96,96,94,95,95,97,104,96&amp;height=30&amp;limits=80,220&amp;upper=90&amp;above-color=rgb(150,150,150)&amp;below-color=z" />
</p>
<p>
  Instead of montonic there do appear to be some bumps, like the little
  jump around the second to the last slide. That slide contains
  the source code to the presentation, so I that slide may have
  gotten a second look, i.e. it was more 'interesting' and 
  people came back to that slide. 
</p>
<p>
  Let's find all those bumps and see what other slides
  count as 'interesting'.
</p>
<p>
  What I'd like to do is process that data so that the bumps
  become pronounced. One way to do that is to take every
  set of 3 adjacent points and calculate:
</p>
<pre>-a[n-1]/2 + a[n] - a[n+1]/2</pre>
<p>
  Now you can look at that as the (negative) acceleration at each point, or you
  can view that as convolving the sample array with the 
  filter (-1/2, 1, -1/2) and wander off into 
  <a href="http://en.wikipedia.org/wiki/Digital_signal_processing">
  Digital Signal Processing</a> territory, but either way you look at it the
  montonic behavior will tend to zero, and the bumps will not. 
</p>
<p>
  So if we update our program to do the above calculation it now looks like:
</p>
<pre>
<span class="PreProc">import</span> re

slide_regex = re.compile(<span class="Normal">"</span><span class="Constant">GET /projects/cascon06/(\d+).html</span><span class="Normal">"</span>)
hits = [0] * 130

<span class="Statement">def</span> <span class="Identifier">analyze</span>(filename):
    <span class="Statement">for</span> line <span class="Statement">in</span> file(filename, <span class="Normal">"</span><span class="Constant">r</span><span class="Normal">"</span>):
        match = slide_regex.search(line)
        <span class="Statement">if</span> match:
            index = int(match.groups()[0])
            <span class="Statement">if</span> index &gt; 0 <span class="Statement">and</span> index &lt; 130:
                hits[int(match.groups()[0])] += 1

    <span class="Comment">#print ",".join([str(i) for i in hits[2:]])</span>

    prefilt = zip(range(len(hits)), hits, hits[1:], hits[2:])

    filt = [(-a/2.0 + b - c/2.0, i+1) <span class="Statement">for</span> (i, a, b, c) <span class="Statement">in</span> prefilt]

    top = sorted(filt)
    top.reverse()

    <span class="Statement">print</span> <span class="Normal">"</span><span class="Constant">Page Weight</span><span class="Normal">"</span>
<span class="Statement">for</span> (weight, index) <span class="Statement">in</span> top[1:8]:
        <span class="Statement">print</span> <span class="Normal">"</span><span class="Constant">%6d %6.1f</span><span class="Normal">"</span> % (index, weight)

analyze(<span class="Normal">"</span><span class="Constant">20061018.log</span><span class="Normal">"</span>)

</pre>
<p>
You'll note that we skip the first page as that
always turns out to be slide number two, which is just an artifact
of <tt>index.html</tt> being an alias for <tt>1.html</tt>.
The output of our program looks like:
</p>
<pre style="background:white;color:black">  Page Weight
     <a href="http://bitworking.org/projects/cascon06/5.html">5</a>   10.5
   <a href="http://bitworking.org/projects/cascon06/128.html">128</a>    7.5
    <a href="http://bitworking.org/projects/cascon06/57.html">57</a>    7.0
    <a href="http://bitworking.org/projects/cascon06/58.html">58</a>    6.0
   <a href="http://bitworking.org/projects/cascon06/113.html">113</a>    5.0
    <a href="http://bitworking.org/projects/cascon06/97.html">97</a>    4.5
    <a href="http://bitworking.org/projects/cascon06/91.html">91</a>    4.0
</pre>
<p>
  The 'interesting' pages include <a href="http://bitworking.org/projects/cascon06/5.html">the jumbled words from Cambridge</a>,
  <a href="http://bitworking.org/projects/cascon06/128.html">the source code to the presentation</a>
<a href="http://bitworking.org/projects/cascon06/57.html">the laws of simplicity</a>,
  and <a href="http://bitworking.org/projects/cascon06/113.html">the assertion that simple means
  the underlying technologies are <em>close to the surface</em></a>. If those pages really 
  were the 'interesting' ones than I'd say my little analysis program, and the presentation
  in general, were a success.
</p>

  
  

