---
title: C10K
date: 2004-11-11T12:00:00-05:00
---

  
  <p>The December issue of Linux Journal was among the newest arrivals in the pile of magazines in the cafeteria this week. 
   In his column "Linux for Suits", <a href="http://doc.weblogs.com/">Doc Searls</a> interviews some of the fine folks at <a href="http://technorati.com">Technorati</a> and talks about
   some of the infrastructure they use. One of the tools mentioned is <a href="http://www.danga.com/memcached/">memcached</a>, 
   <q>a high-performance, distributed memory object caching system, generic in nature, but intended for use in speeding up dynamic web applications by alleviating database load</q>.</p>
<p>But it didn't end there. It never ends there.</p>
<p>Memcached is built on <a href="http://www.monkey.org/~provos/libevent/">libevent</a>, an API that <q> provides a mechanism to execute a callback function when a specific event occurs on a file descriptor or after a timeout has been reached. Furthermore, libevent also support callbacks due to signals or regular timeouts</q>. Now this leads me on a side trip to
  <a href="http://access1.sun.com/techarticles/devpoll.html">/dev/poll</a>, 
  <a href="http://www.xmailserver.org/linux-patches/nio-improve.html">epoll</a>,
  and <a href="http://www.freebsd.org/cgi/man.cgi?query=kqueue&amp;apropos=0&amp;sektion=0&amp;format=html">kqueue/kevent</a>.</p>
<p>Libevent also leads to <a href="http://www.kegel.com/c10k.html">C10K</a>, which is an article on how to configure servers and write code to support thousands of clients:</p>
<blockquote><p>It's time for web servers to handle ten thousand clients simultaneously, don't you think? After all, the web is a big place now.
</p><p>
And computers are big, too. You can buy a 1000MHz machine with 2 gigabytes of RAM and an 1000Mbit/sec Ethernet card for $1200 or so. Let's see - at 20000 clients, that's 50KHz, 100Kbytes, and 50Kbits/sec per client. It shouldn't take any more horsepower than that to take four kilobytes from the disk and send them to the network once a second for each of twenty thousand clients. (That works out to $0.08 per client, by the way. Those $100/client licensing fees some operating systems charge are starting to look a little heavy!) So hardware is no longer the bottleneck.
</p><p>
In 1999 one of the busiest ftp sites, cdrom.com, actually handled 10000 clients simultaneously through a Gigabit Ethernet pipe. As of 2001, that same speed is now being offered by several ISPs, who expect it to become increasingly popular with large business customers. </p></blockquote>
<p>In the <a href="http://www.kegel.com/c10k.html#books">Books to Read First</a> of the C10K paper is a reference to a paper by Welsh, Gibble, Brewer and Culler on <a href="http://www.cs.berkeley.edu/~mdw/papers/events.pdf">A Design Framework for Highly Concurrent Systems (pdf)</a>. So far it is a good read. The downside is that I'm itching to pick up a couple of cheap Debian boxes  and do some experimenting/benchmarking of my own.</p>

  
  

